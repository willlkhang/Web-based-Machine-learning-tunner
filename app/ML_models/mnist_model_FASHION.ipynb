{"cells":[{"metadata":{"jupyter":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"OUdtVbK89ckZ","executionInfo":{"status":"ok","timestamp":1755701920859,"user_tz":-480,"elapsed":18013,"user":{"displayName":"Minh Khang Nguyen","userId":"17151079270851040988"}},"outputId":"e1eab485-1785-47da-b819-1b6e59881a8b"},"cell_type":"code","source":["import torch\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","\n","print(\"DONE\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["DONE\n"]}],"execution_count":1},{"cell_type":"code","metadata":{"jupyter":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"gLboxbCE9ckc","executionInfo":{"status":"ok","timestamp":1755702048020,"user_tz":-480,"elapsed":122159,"user":{"displayName":"Minh Khang Nguyen","userId":"17151079270851040988"}},"outputId":"d7b4c22f-d355-49ce-9c1a-f9f617f7a8cb"},"source":["# Transform to convert images to PyTorch tensors and normalize the data\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","# Load MNIST dataset\n","trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# DataLoader\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n","\n","# Define the Model\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)  # Flatten the images\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = F.log_softmax(self.fc4(x), dim=1)\n","        return x\n","\n","# Initialize the model\n","model = Net()\n","\n","# Loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.003)\n","\n","# Train the Model\n","epochs = 5\n","for e in range(epochs):\n","    running_loss = 0\n","    for images, labels in trainloader:\n","        images = images.view(images.shape[0], -1)  # Flatten MNIST images into a 784 long vector\n","        optimizer.zero_grad()  # Zero the gradients\n","        output = model(images)  # Pass batch\n","        loss = criterion(output, labels)  # Calculate loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","        running_loss += loss.item()  # Add up the loss\n","    print(f\"Training loss: {running_loss/len(trainloader)}\")\n","\n","# Test the Model\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for images, labels in testloader:\n","        images = images.view(images.shape[0], -1)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n","\n","# Save the Trained Model\n","torch.save(model.state_dict(), 'mnist_model.pth')\n","\n","# The saved model can be loaded later with model.load_state_dict(torch.load('mnist_model.pth'))"],"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 26.4M/26.4M [00:03<00:00, 7.65MB/s]\n","100%|██████████| 29.5k/29.5k [00:01<00:00, 23.2kB/s]\n","100%|██████████| 4.42M/4.42M [00:01<00:00, 2.45MB/s]\n","100%|██████████| 5.15k/5.15k [00:00<00:00, 10.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.515259420805013\n","Training loss: 0.39170219952554336\n","Training loss: 0.3573026487440951\n","Training loss: 0.33484169506410294\n","Training loss: 0.3118529701506151\n","Accuracy of the network on the 10000 test images: 86.7%\n"]}],"execution_count":2}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}